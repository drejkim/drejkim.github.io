AndroidWearMotionSensors:
  category: software
  url: /projects/AndroidWearMotionSensors/
  img: https://media.githubusercontent.com/media/estherjk/estherjk.github.io/master/assets/img/projects/AndroidWearMotionSensors.jpg
  description: Using the accelerometer and gyroscope on an Android Wear device
  excerpt: This project displays the raw accelerometer and gyroscope data on an Android Wear device. It also performs simple motion detection&mdash;when a shake or rotation is detected, the background color turns green.
  youtube: https://www.youtube.com/embed/Yxne6YWGbE0
  links:
    -
      name: GitHub
      url: https://github.com/estherjk/AndroidWearMotionSensors
    -
      name: Blog
      url: /blog/2015/02/04/motion-sensors-on-android-wear

edi-cam:
  category: hardware
  url: /projects/edi-cam/
  img: https://media.githubusercontent.com/media/estherjk/estherjk.github.io/master/assets/img/projects/edi-cam.jpg
  description: Video streaming on Intel Edison
  excerpt: This project shows how to stream video to a web browser from a webcam connected to Intel Edison, all while powered by a 9V battery. A Node.js server on Edison listens for the incoming video stream and broadcasts it to all connected browsers via WebSockets. On the client-side, the video is then decoded using jsmpeg and rendered onto an HTML canvas element.
  youtube: https://www.youtube.com/embed/nVDL2-bFT3Y
  links:
    -
      name: GitHub
      url: https://github.com/estherjk/edi-cam
    -
      name: Blog
      url: /blog/2014/12/08/video-streaming-on-edison

edison-arduino101-iot:
  category: hardware
  url: /projects/edison-arduino101-iot/
  img: https://media.githubusercontent.com/media/estherjk/estherjk.github.io/master/assets/img/projects/edison-arduino101-iot.jpg
  description: Edison + Arduino 101 IoT demo
  excerpt: This demo illustrates a simple IoT example by displaying an Arduino 101's IMU (accelerometer / gyroscope) data on a web page. In order to do this, an Intel Edison module is used to receive the data from the Arduino 101 via BLE (Bluetooth Low Energy), then sends it to a web server via WebSockets.
  youtube: https://www.youtube.com/embed/NRZZRsqJQWY
  links:
    -
      name: GitHub
      url: https://github.com/estherjk/edison-arduino101-iot
    -
      name: Blog
      url: /blog/2016/04/08/using-edison-and-arduino-101-together

face-detection-node-opencv:
  category: software
  url: /projects/face-detection-node-opencv/
  img: https://media.githubusercontent.com/media/estherjk/estherjk.github.io/master/assets/img/projects/face-detection-node-opencv.jpg
  description: Real-time face detection using OpenCV, Node.js, and WebSockets
  excerpt: This project performs real-time face detection by using the Node.js bindings for OpenCV. The processed frames are then streamed to a web browser using WebSockets.
  youtube: https://www.youtube.com/embed/v2SY0naPBFw
  links:
    -
      name: GitHub
      url: https://github.com/estherjk/face-detection-node-opencv
    -
      name: Blog
      url: /blog/2014/12/02/real-time-face-detection-using-opencv-nodejs-and-websockets

frogger:
  category: software
  url: /projects/frogger/
  img: https://media.githubusercontent.com/media/estherjk/estherjk.github.io/master/assets/img/projects/frogger.jpg
  description: My final project for Udacity's Object-Oriented JavaScript class
  excerpt: The purpose of this class is to learn the best practices of object-oriented JavaScript by building an implementation of the classic arcade game, Frogger.
  youtube: https://www.youtube.com/embed/dIu40myH9CY
  links:
    -
      name: Site
      url: https://esthermakes.tech/frogger/
    -
      name: GitHub
      url: https://github.com/estherjk/frogger

google-assistant-show:
  category: hardware
  url: /projects/google-assistant-show/
  img: https://media.githubusercontent.com/media/estherjk/estherjk.github.io/master/assets/img/projects/google-assistant-show.jpg
  description: Using the Android Things Kit to create a touch screen interface for Google Assistant
  excerpt: Google Assistant Show is a touch interface for Google Assistant. The NXP i.MX7D Starter Kit was used for this project. It comes with a touch display, 3.5 mm analog output (for audio), and a USB port (for this project, a USB mic was connected to it). How it works... a user taps the button on the touch display to start the request, the user says something, and Google responds! The display also updates with the request and response.
  youtube: https://www.youtube.com/embed/Igml_TgM1L8
  links:
    -
      name: GitHub
      url: https://github.com/estherjk/google-assistant-show

HackerBoxCar:
  category: hardware
  url: /projects/HackerBoxCar/
  img: https://media.githubusercontent.com/media/estherjk/estherjk.github.io/master/assets/img/projects/HackerBoxCar.jpg
  description: My implementation of the Autosport HackerBox
  excerpt: The project uses the Autosport HackerBox kit and is capable of three modes... remote control, line-following, and autonomous. In remote-control mode, the car uses a companion mobile app to control its movements. In line-following mode, a pair of IR sensors detect a black line to control its path. In autonomous mode, an ultrasonic range sensor detects objects and attempts to avoid them.
  youtube: https://www.youtube.com/embed/K7Yosm08pu0
  links:
    -
      name: GitHub
      url: https://github.com/estherjk/HackerBoxCar
    -
      name: Blog
      url: /blog/2017/07/03/my-experience-with-the-hackerbox-autosport-kit/
  showcase: true

led-speech-edison:
  category: hardware
  url: /projects/led-speech-edison/
  img: https://media.githubusercontent.com/media/estherjk/estherjk.github.io/master/assets/img/projects/led-speech-edison.jpg
  description: Speech-activated LEDs using Intel Edison, SparkFun blocks, Python, and CMU Sphinx
  excerpt: This project combines basic circuit design and Python programming to control 4 LEDs by speech. It also uses CMU Sphinx, a speech recognition engine from Carnegie Mellon University.
  youtube: https://www.youtube.com/embed/kVTV_qZtwlY
  links:
    -
      name: GitHub
      url: https://github.com/estherjk/led-speech-edison
    -
      name: Blog
      url: /blog/2015/04/15/speech-activated-leds-using-intel-edison

LediMote:
  category: hardware
  url: /projects/LediMote/
  img: https://media.githubusercontent.com/media/estherjk/estherjk.github.io/master/assets/img/projects/LediMote.jpg
  description: Remote-controlled LEDs using Intel Edison and Node.js (for web, iOS, and Android)
  excerpt: This project illustrates how to turn on and off LEDs from a web page, an iOS app, or an Android app using Intel Edison.
  youtube: https://www.youtube.com/embed/i61g4aYkrI0
  links:
    -
      name: GitHub
      url: https://github.com/estherjk/LediMote
    -
      name: Blog
      url: /blog/2015/06/25/ledimote-remote-controlled-leds-using-intel-edison-and-nodejs

multi-screen-demo:
  category: software
  url: /projects/multi-screen-demo/
  img: https://media.githubusercontent.com/media/estherjk/estherjk.github.io/master/assets/img/projects/multi-screen-demo.jpg
  description: Controlling your PC web browser from your mobile phone
  excerpt: multi-screen-demo is a Node.js / AngularJS app that uses socket.io (WebSockets) to pair a mobile and a PC. The app contains two demos. The first uses gestures on a mobile and shows the detected events on a paired PC. The second uses a simple D-pad controller on a mobile to move a target around on a paired PC.
  youtube: https://www.youtube.com/embed/7O-rgDwTI9I
  links:
    -
      name: Site
      url: https://esthermakes.tech/multi-screen-demo/
    -
      name: GitHub
      url: https://github.com/estherjk/multi-screen-demo
    -
      name: Blog
      url: /blog/2014/02/24/using-websockets-for-developing-multi-screen-user-experiences

O Holy Night:
  category: hardware
  url: /projects/o-holy-night/
  img: https://media.githubusercontent.com/media/estherjk/estherjk.github.io/master/assets/img/projects/o-holy-night.jpg
  description: Recreating the Nativity Scene using the Particle Photon and NeoPixels
  excerpt: This project uses familiar ingredients, namely the Particle Photon and NeoPixels, and some paper cutouts to recreate the Nativity Scene. The lights are controlled with a custom iOS app.
  youtube: https://www.youtube.com/embed/TUcphhJK0uM
  links:
    -
      name: GitHub
      url: https://github.com/estherjk/o-holy-night
    -
      name: Blog
      url: /blog/2016/12/23/o-holy-night/

ok-google-pi-zero:
  category: hardware
  url: /projects/ok-google-pi-zero/
  img: https://media.githubusercontent.com/media/estherjk/estherjk.github.io/master/assets/img/projects/ok-google-pi-zero.jpg
  description: Using the Google Assistant SDK on a Raspberry Pi Zero W
  excerpt: In other words, I'm making my own Google Home Mini. This project is still a work in progress, but the plan is to flesh it out and extend its capabilities.
  youtube: https://www.youtube.com/embed/ciiGTOzrDcc
  links:
    -
      name: GitHub
      url: https://github.com/estherjk/ok-google-pi-zero

particle-light-alexa:
  category: hardware
  url: /projects/particle-light-alexa/
  img: https://media.githubusercontent.com/media/estherjk/estherjk.github.io/master/assets/img/projects/particle-light-alexa.jpg
  description: Asking Amazon Alexa to control a light ft. NeoPixels and Particle Photon
  excerpt: Ask Amazon Alexa to control a light. In this case, the "light" is a NeoPixel ring connected to a Particle Photon. The functions to control the light are exposed through the <a href="https://docs.particle.io/reference/firmware/photon/#particle-function-">Particle Cloud</a>. The Alexa skill then calls the functions using the <a href="https://docs.particle.io/reference/javascript/#callfunction">JavaScript Particle API</a>. This project has also been featured on <a href="https://blog.hackster.io/hacksters-handpicked-projects-of-the-week-c8045ee5cfe5">Hackster's Handpicked Projects of the Week</a>.
  youtube: https://www.youtube.com/embed/y9VvusYF1sg
  links:
    -
      name: GitHub
      url: https://github.com/estherjk/particle-light-alexa
    -
      name: Blog
      url: /blog/2016/09/10/alexa-turn-on-the-light/
  showcase: true

particle-weather-station:
  category: hardware
  url: /projects/particle-weather-station/
  img: https://media.githubusercontent.com/media/estherjk/estherjk.github.io/master/assets/img/projects/particle-weather-station.jpg
  description: Monitoring temperature and humidity using the Particle Photon
  excerpt: Create your own weather station with the Particle Photon board. A DHT11 sensor is used to measure temperature and humidity. Ubidots, a cloud service, is then used to visualize the data in real time.
  youtube: https://www.youtube.com/embed/XKxeXtfn4MM
  links:
    -
      name: GitHub
      url: https://github.com/estherjk/particle-weather-station
    -
      name: Blog
      url: /blog/2016/05/25/monitoring-temperature-and-humidity-using-the-particle-photon

particle-weather-station-alexa:
  category: hardware
  url: /projects/particle-weather-station-alexa/
  img: https://media.githubusercontent.com/media/estherjk/estherjk.github.io/master/assets/img/projects/particle-weather-station-alexa.jpg
  description: Asking Amazon Alexa for the temperature and humidity from a Particle Photon
  excerpt: This project integrates Amazon Alexa to the original <a href="/projects/particle-weather-station/">particle-weather-station</a> project. Instead of visualizing the data on a dashboard, you can ask Alexa for the current temperature or humidity. To communicate the data between Particle and Alexa, the variables are exposed through the <a href="https://docs.particle.io/reference/firmware/photon/#particle-variable-">Particle Cloud</a>, then the Alexa skill gets the data using the <a href="https://docs.particle.io/reference/javascript/">JavaScript Particle API</a>.
  youtube: https://www.youtube.com/embed/j5CpMcM5yRI
  links:
    -
      name: GitHub
      url: https://github.com/estherjk/particle-weather-station-alexa
    -
      name: Blog
      url: /blog/2016/08/30/asking-alexa-for-the-temperature-and-humidity-from-a-particle-photon

Potter Pi:
  category: software
  url: /projects/potter-pi/
  img: https://media.githubusercontent.com/media/estherjk/estherjk.github.io/master/assets/img/projects/potter-pi.jpg
  description: I solemnly swear that I am up to no good.
  excerpt: Not sure what to do with your wand after a trip to the Wizarding World of Harry Potter? Try this project. You can control smart home elements by casting spells. The IR Camera System is built with a Raspberry Pi Zero, a NoIR camera, & a couple IR LEDs. The software is built with Python, OpenCV, TensorFlow, & the Home Assistant REST API.
  youtube: https://www.youtube.com/embed/videoseries?list=PLptYOcdK9JEyvkCDLd1lmca2Ad2-JoiTL
  links:
    -
      name: GitHub
      url: https://github.com/estherjk/potter-pi
    -
      name: Blog
      url: /blog/2019/10/20/introducing-potter-pi/
  showcase: true

Reading Quantified:
  category: software
  url: /projects/reading-quantified/
  img: https://media.githubusercontent.com/media/estherjk/estherjk.github.io/master/assets/img/projects/reading-quantified-ios.jpg
  description: Analyzing my reading habits
  excerpt: This project analyzes and visualizes my reading habits. The YouTube playlist is a collection of the various iterations of this project over the years. The web version originally used Node.js, Parse, Angular, & d3; it was completely overhauled to use Django, PostgreSQL, & Metabase. The most recent edition is an iOS app written in Swift.
  youtube: https://www.youtube.com/embed/videoseries?list=PLptYOcdK9JEy28FvDq4XTP2j4ckuTH6B9
  links:
    -
      name: Site
      url: https://esthermakes.tech/reading-quantified/
    -
      name: GitHub
      url: https://github.com/estherjk/reading-quantified
    -
      name: Blog
      url: /blog/2019/06/11/reading-quantifed-ios-edition/
  showcase: true

rte-angular:
  category: software
  url: /projects/rte-angular/
  img: https://media.githubusercontent.com/media/estherjk/estherjk.github.io/master/assets/img/projects/rte-angular.jpg
  description: An AngularJS rich-text editor
  excerpt: This is a custom AngularJS directive for adding a rich-text editor to your web page. It includes all the basic text formatting options, as well as the ability to include image and video links.
  youtube: https://www.youtube.com/embed/G9czu0WwKVA
  links:
    -
      name: Site
      url: https://esthermakes.tech/rte-angular/
    -
      name: GitHub
      url: https://github.com/estherjk/rte-angular
